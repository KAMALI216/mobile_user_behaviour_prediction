{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "861ae1d7-27f9-4b9a-9d55-01d560922124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load datasets\n",
    "static = pd.read_csv(\"expanded_user_behavior_dataset.csv\")\n",
    "behav = pd.read_csv(\"mobile_usage_behavioral_analysis.csv\")\n",
    "\n",
    "# Merge on User ID\n",
    "df_static = static.merge(behav.rename(columns={\"User_ID\": \"User ID\"}), on=\"User ID\", how=\"inner\")\n",
    "\n",
    "# Encode categorical features\n",
    "enc_dev = LabelEncoder().fit(df_static[\"Device Model\"])\n",
    "enc_os = LabelEncoder().fit(df_static[\"Operating System\"])\n",
    "enc_gender = LabelEncoder().fit(df_static[\"Gender_x\"])\n",
    "\n",
    "df_static[\"Device Model\"] = enc_dev.transform(df_static[\"Device Model\"])\n",
    "df_static[\"Operating System\"] = enc_os.transform(df_static[\"Operating System\"])\n",
    "df_static[\"Gender\"] = enc_gender.transform(df_static[\"Gender_x\"])\n",
    "\n",
    "# Save encoders\n",
    "joblib.dump(enc_dev, \"enc_device.joblib\")\n",
    "joblib.dump(enc_os, \"enc_os.joblib\")\n",
    "joblib.dump(enc_gender, \"enc_gender.joblib\")\n",
    "\n",
    "# Select 9 static input features\n",
    "X_static = df_static[[\n",
    "    \"Device Model\", \"Operating System\", \"Gender\",\n",
    "    \"App Usage Time (min/day)\", \"Screen On Time (hours/day)\",\n",
    "    \"Battery Drain (mAh/day)\", \"Number of Apps Installed\",\n",
    "    \"Data Usage (MB/day)\", \"Age_x\"\n",
    "]].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler().fit(X_static)\n",
    "X_static = scaler.transform(X_static)\n",
    "joblib.dump(scaler, \"scaler_static.joblib\")\n",
    "\n",
    "# Target\n",
    "# Target labels (convert from 1-5 to 0-4)\n",
    "y = df_static[\"User Behavior Class\"].values - 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38b7f258-1ffe-4912-9ff8-b808f81bc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic sequence data (7 days, 3 features)\n",
    "SEQ_LEN = 7\n",
    "SEQ_FEAT = 3\n",
    "seq_tensor = np.random.rand(len(df_static), SEQ_LEN, SEQ_FEAT)\n",
    "\n",
    "# Encode user IDs\n",
    "user_ids = df_static[\"User ID\"].values\n",
    "user_ids = LabelEncoder().fit_transform(user_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4113162-4c5f-410f-b30f-3d845956f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_uid_train, X_uid_val, X_stat_train, X_stat_val, X_seq_train, X_seq_val, y_train, y_val = train_test_split(\n",
    "    user_ids, X_static, seq_tensor, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86134804-908c-465a-8b13-37f59bfd8ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_id             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,008</span> │ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │          \u001b[38;5;34m6\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_id             │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │         \u001b[38;5;34m93\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m8,008\u001b[0m │ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m1,344\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m165\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,696</span> (45.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,696\u001b[0m (45.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,696</span> (45.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,696\u001b[0m (45.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D, Flatten, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Inputs\n",
    "uid_input = Input(shape=(), dtype=tf.int32, name=\"user_id\")\n",
    "static_input = Input(shape=(9,), name=\"static_input\")\n",
    "seq_input = Input(shape=(SEQ_LEN, SEQ_FEAT), name=\"sequence_input\")\n",
    "\n",
    "# User embedding\n",
    "uid_embedding = Embedding(input_dim=len(np.unique(user_ids)) + 1, output_dim=8)(uid_input)\n",
    "uid_flat = Flatten()(uid_embedding)\n",
    "\n",
    "# Transformer encoder\n",
    "x = LayerNormalization()(seq_input)\n",
    "x = MultiHeadAttention(num_heads=2, key_dim=SEQ_FEAT)(x, x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Concatenate all\n",
    "combined = Concatenate()([uid_flat, static_input, x])\n",
    "x = Dense(64, activation='relu')(combined)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(5, activation='softmax')(x)  # 5 classes\n",
    "\n",
    "model = Model(inputs=[uid_input, static_input, seq_input], outputs=output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2d82b26-4fe8-4d96-8595-c6057d92bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - accuracy: 0.2765 - loss: 1.5464 - val_accuracy: 0.4650 - val_loss: 1.2969\n",
      "Epoch 2/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4769 - loss: 1.2585 - val_accuracy: 0.5200 - val_loss: 1.0701\n",
      "Epoch 3/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5899 - loss: 1.0427 - val_accuracy: 0.6800 - val_loss: 0.8749\n",
      "Epoch 4/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6658 - loss: 0.8659 - val_accuracy: 0.8150 - val_loss: 0.7108\n",
      "Epoch 5/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7837 - loss: 0.7097 - val_accuracy: 0.9150 - val_loss: 0.5619\n",
      "Epoch 6/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8540 - loss: 0.5703 - val_accuracy: 0.9450 - val_loss: 0.4314\n",
      "Epoch 7/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8719 - loss: 0.4492 - val_accuracy: 0.9600 - val_loss: 0.3218\n",
      "Epoch 8/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9017 - loss: 0.3569 - val_accuracy: 0.9950 - val_loss: 0.2403\n",
      "Epoch 9/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.2543 - val_accuracy: 0.9900 - val_loss: 0.1836\n",
      "Epoch 10/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9609 - loss: 0.2113 - val_accuracy: 0.9850 - val_loss: 0.1620\n",
      "Epoch 11/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1934 - val_accuracy: 0.9950 - val_loss: 0.1216\n",
      "Epoch 12/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9635 - loss: 0.1496 - val_accuracy: 0.9850 - val_loss: 0.1292\n",
      "Epoch 13/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1355 - val_accuracy: 0.9950 - val_loss: 0.0966\n",
      "Epoch 14/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.1000 - val_accuracy: 0.9950 - val_loss: 0.0839\n",
      "Epoch 15/15\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9900 - loss: 0.0866 - val_accuracy: 0.9850 - val_loss: 0.0806\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [X_uid_train, X_stat_train, X_seq_train], y_train,\n",
    "    validation_data=([X_uid_val, X_stat_val, X_seq_val], y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"user_behavior_transformer_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df34533-9276-4d14-ac90-d230189fa70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Training Accuracy: 0.9862\n",
      "✅ Final Validation Accuracy: 0.9850\n"
     ]
    }
   ],
   "source": [
    "# Print final training and validation accuracy\n",
    "final_train_acc = history.history['accuracy'][-1]\n",
    "final_val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"✅ Final Training Accuracy: {final_train_acc:.4f}\")\n",
    "print(f\"✅ Final Validation Accuracy: {final_val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12cf8d36-96c3-4acc-b6ea-968ef9d6cc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Saved Keras Models:\n",
      " - .keras\n",
      " - user_behavior_transformer_model.h5\n",
      " - user_behavior_transformer_model.keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_files = [f for f in os.listdir() if f.endswith('.keras') or f.endswith('.h5')]\n",
    "print(\"📦 Saved Keras Models:\")\n",
    "for f in model_files:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "412d5b9a-34f0-4e99-a52d-7ce622f0c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ScreenBatteryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=heads, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, 2)  # 2 outputs: screen_time, battery_drain\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x).unsqueeze(1)  # (batch_size, 1, embed_dim)\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(1)  # (batch_size, embed_dim)\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2db42773-749e-44ee-b6be-156537679095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_expanded  = pd.read_csv(\"expanded_user_behavior_dataset.csv\")          # file 1\n",
    "df_behavior  = pd.read_csv(\"mobile_usage_behavioral_analysis.csv\")        # file 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0422a2ec-6f30-44bc-a9d5-d5bf259d0489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_expanded.merge(\n",
    "        df_behavior,\n",
    "        left_on=\"User ID\",   # from file 1\n",
    "        right_on=\"User_ID\",  # from file 2\n",
    "        how=\"inner\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "356c202c-2332-456a-b476-ee9891c0b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Gender column from file 1 (Gender_x after merge)\n",
    "df[\"Gender\"] = df[\"Gender_x\"].map({\"Male\": 0, \"Female\": 1})\n",
    "\n",
    "# Select and rename the 11 features you need\n",
    "df1 = df.rename(columns={\n",
    "        \"App Usage Time (min/day)\"       : \"app_usage_min\",\n",
    "        \"Number of Apps Installed\"       : \"apps_installed\",\n",
    "        \"Data Usage (MB/day)\"            : \"data_usage\",\n",
    "        \"Age_x\"                          : \"age\",\n",
    "        \"Total_App_Usage_Hours\"          : \"total_app_usage\",\n",
    "        \"Daily_Screen_Time_Hours\"        : \"daily_screen_time\",\n",
    "        \"Social_Media_Usage_Hours\"       : \"social\",\n",
    "        \"Productivity_App_Usage_Hours\"   : \"productivity\",\n",
    "        \"Gaming_App_Usage_Hours\"         : \"gaming\",\n",
    "        \"User Behavior Class\"            : \"user_behavior_class\"\n",
    "})\n",
    "\n",
    "# Keep only the 11 columns in the right order\n",
    "feature_cols = [\n",
    "    \"app_usage_min\", \"apps_installed\", \"data_usage\", \"age\",\n",
    "    \"Gender\", \"total_app_usage\", \"daily_screen_time\",\n",
    "    \"social\", \"productivity\", \"gaming\", \"user_behavior_class\"\n",
    "]\n",
    "df1 = df1[feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f7a243a0-ad87-491a-bd92-16fedf46cb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   app_usage_min  apps_installed  data_usage  age  Gender  total_app_usage  \\\n",
      "0            393              67        1122   40       0             2.61   \n",
      "1            268              42         944   47       1             2.13   \n",
      "2            154              32         322   42       0             7.28   \n",
      "3            239              56         871   20       0             1.20   \n",
      "4            187              58         988   31       1             6.31   \n",
      "\n",
      "   daily_screen_time  social  productivity  gaming  user_behavior_class  \n",
      "0               7.15    4.43          0.55    2.40                    4  \n",
      "1              13.79    4.67          4.42    2.43                    3  \n",
      "2               4.50    4.58          1.71    2.83                    2  \n",
      "3               6.29    3.18          3.42    4.58                    3  \n",
      "4              12.59    3.15          0.13    4.00                    3  \n",
      "Shape: (1000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df1.head())\n",
    "print(\"Shape:\", df1.shape)   # (rows, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87abef1e-1268-4ac8-8d2c-09eb9e99a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1504635.5000\n",
      "Epoch 10, Loss: 1497469.7500\n",
      "Epoch 20, Loss: 1496435.8750\n",
      "Epoch 30, Loss: 1495293.7500\n",
      "Epoch 40, Loss: 1494043.8750\n",
      "Epoch 50, Loss: 1492665.8750\n",
      "Epoch 60, Loss: 1491241.6250\n",
      "Epoch 70, Loss: 1489721.8750\n",
      "Epoch 80, Loss: 1488118.3750\n",
      "Epoch 90, Loss: 1486417.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['screen_battery_scaler.joblib']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ────── 1. Load and merge datasets ──────\n",
    "df_expanded  = pd.read_csv(\"expanded_user_behavior_dataset.csv\")\n",
    "df_behavior  = pd.read_csv(\"mobile_usage_behavioral_analysis.csv\")\n",
    "\n",
    "df = df_expanded.merge(df_behavior, left_on=\"User ID\", right_on=\"User_ID\", how=\"inner\")\n",
    "df[\"gender\"] = df[\"Gender_x\"].map({\"Male\": 0, \"Female\": 1})\n",
    "\n",
    "# Rename & select only the features\n",
    "df1 = df.rename(columns={\n",
    "    \"App Usage Time (min/day)\"     : \"app_usage_min\",\n",
    "    \"Number of Apps Installed\"     : \"apps_installed\",\n",
    "    \"Data Usage (MB/day)\"          : \"data_usage\",\n",
    "    \"Age_x\"                        : \"age\",\n",
    "    \"Total_App_Usage_Hours\"        : \"total_app_usage\",\n",
    "    \"Daily_Screen_Time_Hours\"      : \"daily_screen_time\",\n",
    "    \"Social_Media_Usage_Hours\"     : \"social\",\n",
    "    \"Productivity_App_Usage_Hours\" : \"productivity\",\n",
    "    \"Gaming_App_Usage_Hours\"       : \"gaming\",\n",
    "    \"User Behavior Class\"          : \"user_behavior_class\",\n",
    "    \"Screen On Time (hours/day)\"   : \"screen_on_time\",\n",
    "    \"Battery Drain (mAh/day)\"      : \"battery_drain\"\n",
    "})\n",
    "\n",
    "# ────── 2. Prepare features and target ──────\n",
    "feature_cols = [\n",
    "    \"app_usage_min\", \"apps_installed\", \"data_usage\", \"age\", \"gender\",\n",
    "    \"total_app_usage\", \"daily_screen_time\", \"social\", \"productivity\",\n",
    "    \"gaming\", \"user_behavior_class\"\n",
    "]\n",
    "target_cols = [\"screen_on_time\", \"battery_drain\"]\n",
    "\n",
    "X = df1[feature_cols].values\n",
    "y = df1[target_cols].values\n",
    "\n",
    "# ────── 3. Scale features ──────\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ────── 4. Train/test split (optional but recommended) ──────\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ────── 5. Convert to PyTorch tensors ──────\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "# ────── 6. Define model ──────\n",
    "class ScreenBatteryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, 2)  # screen_time, battery_drain\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x).unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(1)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "model = ScreenBatteryTransformer(input_dim=11)\n",
    "\n",
    "# ────── 7. Loss & optimizer ──────\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ────── 8. Training loop ──────\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(X_tensor)\n",
    "    loss = criterion(preds, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ────── 9. Save model and scaler ──────\n",
    "torch.save(model.state_dict(), \"screen_battery_transformer.pt\")\n",
    "import joblib\n",
    "joblib.dump(scaler, \"screen_battery_scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "01d7db7d-d0d7-4ce1-a798-c1c6d2a27d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset saved as 'merged_behavior_battery_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first two datasets\n",
    "df1 = pd.read_csv(\"expanded_user_behavior_dataset.csv\")\n",
    "df2 = pd.read_csv(\"mobile_usage_behavioral_analysis.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df1.rename(columns={\n",
    "    \"User ID\": \"user_id\",\n",
    "    \"App Usage Time (min/day)\": \"app_usage_min\",\n",
    "    \"Screen On Time (hours/day)\": \"screen_on_time\",\n",
    "    \"Battery Drain (mAh/day)\": \"battery_drain\",\n",
    "    \"Number of Apps Installed\": \"apps_installed\",\n",
    "    \"Data Usage (MB/day)\": \"data_usage\",\n",
    "    \"Age\": \"age\",\n",
    "    \"Gender\": \"gender\",\n",
    "    \"User Behavior Class\": \"user_behavior_class\"\n",
    "}, inplace=True)\n",
    "\n",
    "df2.rename(columns={\n",
    "    \"User_ID\": \"user_id\",\n",
    "    \"Total_App_Usage_Hours\": \"total_app_usage\",\n",
    "    \"Daily_Screen_Time_Hours\": \"daily_screen_time\",\n",
    "    \"Social_Media_Usage_Hours\": \"social\",\n",
    "    \"Productivity_App_Usage_Hours\": \"productivity\",\n",
    "    \"Gaming_App_Usage_Hours\": \"gaming\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge df1 and df2 on user_id\n",
    "merged_df = pd.merge(df1, df2, on=\"user_id\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df = merged_df[[\n",
    "    \"app_usage_min\", \"apps_installed\", \"data_usage\", \"age\",\n",
    "    \"gender\", \"total_app_usage\", \"daily_screen_time\",\n",
    "    \"social\", \"productivity\", \"gaming\", \"user_behavior_class\",\n",
    "    \"screen_on_time\", \"battery_drain\"\n",
    "]]\n",
    "\n",
    "# Encode gender\n",
    "merged_df[\"gender\"] = merged_df[\"gender\"].map({\"Male\": 1, \"Female\": 0})\n",
    "\n",
    "# Save for later use\n",
    "merged_df.to_csv(\"merged_behavior_battery_dataset.csv\", index=False)\n",
    "\n",
    "print(\"✅ Merged dataset saved as 'merged_behavior_battery_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "abca206e-008f-469b-8611-98bb0c0277f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"merged_behavior_battery_dataset.csv\")\n",
    "# Proceed with training your ScreenBatteryTransformer model...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d29c6d32-29b6-42aa-91e9-3f595cbeff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scaler saved: screen_battery_scaler.joblib\n",
      "Epoch   1 | Train Loss: 1505266.5000 | Val Loss: 1443951.5000\n",
      "Epoch  10 | Train Loss: 1497751.2500 | Val Loss: 1440516.5000\n",
      "Epoch  20 | Train Loss: 1496737.7500 | Val Loss: 1439471.3750\n",
      "Epoch  30 | Train Loss: 1495638.5000 | Val Loss: 1438358.1250\n",
      "Epoch  40 | Train Loss: 1494422.5000 | Val Loss: 1437161.8750\n",
      "Epoch  50 | Train Loss: 1493071.0000 | Val Loss: 1435875.8750\n",
      "Epoch  60 | Train Loss: 1491653.5000 | Val Loss: 1434488.1250\n",
      "Epoch  70 | Train Loss: 1490141.0000 | Val Loss: 1433005.5000\n",
      "Epoch  80 | Train Loss: 1488541.5000 | Val Loss: 1431433.5000\n",
      "Epoch  90 | Train Loss: 1486848.6250 | Val Loss: 1429775.0000\n",
      "Epoch 100 | Train Loss: 1485066.8750 | Val Loss: 1428030.1250\n",
      "Epoch 110 | Train Loss: 1483189.5000 | Val Loss: 1426200.7500\n",
      "Epoch 120 | Train Loss: 1481241.6250 | Val Loss: 1424287.6250\n",
      "✅ Model weights saved: screen_battery_transformer_11.pt\n"
     ]
    }
   ],
   "source": [
    "# train_screen_battery_transformer.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# ───────────────── 1. Load merged dataset ─────────────────\n",
    "df = pd.read_csv(\"merged_behavior_battery_dataset.csv\")\n",
    "\n",
    "feature_cols = [\n",
    "    \"app_usage_min\", \"apps_installed\", \"data_usage\", \"age\",\n",
    "    \"gender\", \"total_app_usage\", \"daily_screen_time\",\n",
    "    \"social\", \"productivity\", \"gaming\", \"user_behavior_class\"\n",
    "]\n",
    "target_cols = [\"screen_on_time\", \"battery_drain\"]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df[target_cols].values\n",
    "\n",
    "# ───────────────── 2. Scale features & save scaler ─────────────────\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"screen_battery_scaler.joblib\")\n",
    "print(\"✅ Scaler saved: screen_battery_scaler.joblib\")\n",
    "\n",
    "# ───────────────── 3. Train/Test split ─────────────────\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
    "y_val_t   = torch.tensor(y_val,   dtype=torch.float32)\n",
    "\n",
    "# ───────────────── 4. Define Transformer Regressor ─────────────────\n",
    "class ScreenBatteryTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=64, heads=4, layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=heads, batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=layers)\n",
    "        self.out = nn.Linear(embed_dim, 2)  # screen_time & battery_drain\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x).unsqueeze(1)  # (B,1,E)\n",
    "        x = self.encoder(x).squeeze(1)       # (B,E)\n",
    "        return self.out(x)\n",
    "\n",
    "model = ScreenBatteryTransformer(input_dim=11)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ───────────────── 5. Training loop ─────────────────\n",
    "EPOCHS = 120\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X_train_t)\n",
    "    loss = criterion(pred, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # --- Validate ---\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_t)\n",
    "            val_loss = criterion(val_pred, y_val_t).item()\n",
    "        print(f\"Epoch {epoch:3d} | Train Loss: {loss.item():.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# ───────────────── 6. Save model weights ─────────────────\n",
    "torch.save(model.state_dict(), \"screen_battery_transformer_11.pt\")\n",
    "print(\"✅ Model weights saved: screen_battery_transformer_11.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579ac13-1189-453f-b10e-35836b8f64fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
